{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82abbd78",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This notebook takes the manifest and uses to embed all core documents + citations avaible in a FAISS vector databse with langchain and granite-embedding:30m\n",
    "\n",
    "```\n",
    "ollama pull nomic-embed-text:v1.5\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8d0e07",
   "metadata": {},
   "source": [
    "### Importing and Paths\n",
    "\n",
    "Change the ROOT  paths as needed. It should point to to the main knowledge pack dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad972735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ktejwani/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/first_aid_knowledge_pack_v3\n",
      "/Users/ktejwani/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/first_aid_knowledge_pack_v3/manifest.yaml\n"
     ]
    }
   ],
   "source": [
    "# --- A. Imports & config ---\n",
    "from pathlib import Path\n",
    "import json, hashlib, uuid, yaml\n",
    "from typing import List, Dict\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Paths (adapt for your pack root)\n",
    "ROOT = Path(\"/Users/ktejwani/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/first_aid_knowledge_pack_v3\")\n",
    "MANIFEST = ROOT / \"manifest.yaml\"\n",
    "print(ROOT)\n",
    "print(MANIFEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbb7439",
   "metadata": {},
   "source": [
    "### Parsing YAML, Embedding Documents, and Creating Vector Store\n",
    "\n",
    "NOTES: \n",
    "1. Below cell will create a new directory inisde the knolwedge pack:\n",
    "- Example: first_aid_pack_demo_v2/vector_db/text/faiss_index <br>\n",
    "This directory will have the actual .faiss store and index pickle file\n",
    "\n",
    "2. embeddings.jsonl, index.bin, and meta.json under first_aid_pack_demo_v2/vector_db/text/faiss_index will be overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d36beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FAISS dir: /Users/ktejwani/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/first_aid_knowledge_pack_v3/vector_db/text/faiss_index\n",
      "Embeddings JSONL: /Users/ktejwani/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/first_aid_knowledge_pack_v3/vector_db/text/embeddings.jsonl\n",
      "Meta JSON: /Users/ktejwani/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/first_aid_knowledge_pack_v3/vector_db/text/meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwriting cache for 0 5692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! PDF has no extractable text (scanned images?): /Users/ktejwani/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/first_aid_knowledge_pack_v3/core/rash/hi_en/IntegratedPartheniumManagement(Elglish)-Folder.pdf\n",
      "! PDF has no extractable text (scanned images?): /Users/ktejwani/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/first_aid_knowledge_pack_v3/core/wild-animals/hi_en/Advisory for Priority of Action for State Govt-Human Wildlife Conflict_0.pdf\n",
      "! PDF has no extractable text (scanned images?): /Users/ktejwani/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/first_aid_knowledge_pack_v3/core/transport/hi_en/SOP-OF-AMBULANCE2020IPTHHScompressed.pdf\n",
      "! PDF has no extractable text (scanned images?): /Users/ktejwani/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/first_aid_knowledge_pack_v3/core/contacts/hi_en/phc_list_bihar.pdf\n",
      "! Skipping missing file: /core/education/hi_en/User_Manual_for_BSCCpdf1.pdf\n",
      "Prepared 6889 chunks from 31 files (PDFs with no text skipped: 4)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 197\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# --- Embeddings + FAISS persist ---\u001b[39;00m\n\u001b[32m    196\u001b[39m emb = OllamaEmbeddings(model=embed_model_name)\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m vs = \u001b[43mFAISS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m vs.save_local(\u001b[38;5;28mstr\u001b[39m(faiss_dir))  \u001b[38;5;66;03m# writes index.faiss + index.pkl\u001b[39;00m\n\u001b[32m    200\u001b[39m \u001b[38;5;66;03m# sanity check\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/venv/lib/python3.13/site-packages/langchain_core/vectorstores/base.py:848\u001b[39m, in \u001b[36mVectorStore.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, **kwargs)\u001b[39m\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[32m    846\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m] = ids\n\u001b[32m--> \u001b[39m\u001b[32m848\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/venv/lib/python3.13/site-packages/langchain_community/vectorstores/faiss.py:1043\u001b[39m, in \u001b[36mFAISS.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_texts\u001b[39m(\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1023\u001b[39m     **kwargs: Any,\n\u001b[32m   1024\u001b[39m ) -> FAISS:\n\u001b[32m   1025\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[32m   1026\u001b[39m \n\u001b[32m   1027\u001b[39m \u001b[33;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1041\u001b[39m \u001b[33;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m     embeddings = \u001b[43membedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1044\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__from(\n\u001b[32m   1045\u001b[39m         texts,\n\u001b[32m   1046\u001b[39m         embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1050\u001b[39m         **kwargs,\n\u001b[32m   1051\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/venv/lib/python3.13/site-packages/langchain_ollama/embeddings.py:284\u001b[39m, in \u001b[36mOllamaEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    279\u001b[39m     msg = (\n\u001b[32m    280\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOllama client is not initialized. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    281\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure Ollama is running and the model is loaded.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    282\u001b[39m     )\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_default_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkeep_alive\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/venv/lib/python3.13/site-packages/ollama/_client.py:367\u001b[39m, in \u001b[36mClient.embed\u001b[39m\u001b[34m(self, model, input, truncate, options, keep_alive)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed\u001b[39m(\n\u001b[32m    360\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    361\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    365\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    366\u001b[39m ) -> EmbedResponse:\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m    \u001b[49m\u001b[43mEmbedResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/embed\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEmbedRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/venv/lib/python3.13/site-packages/ollama/_client.py:180\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    176\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    178\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/venv/lib/python3.13/site-packages/ollama/_client.py:120\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    119\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     r = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m     r.raise_for_status()\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/venv/lib/python3.13/site-packages/httpx/_client.py:825\u001b[39m, in \u001b[36mClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    810\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m    812\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    813\u001b[39m     method=method,\n\u001b[32m    814\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    823\u001b[39m     extensions=extensions,\n\u001b[32m    824\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/venv/lib/python3.13/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/venv/lib/python3.13/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/venv/lib/python3.13/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/venv/lib/python3.13/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/venv/lib/python3.13/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/venv/lib/python3.13/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/venv/lib/python3.13/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "with open(MANIFEST, \"r\", encoding=\"utf-8\") as f:\n",
    "    manifest = yaml.safe_load(f)\n",
    "\n",
    "# Pull embedding config from manifest\n",
    "embed_model_name = manifest[\"embedding_config\"][\"text\"][\"model\"]     # e.g., \"granite-embedding:278m\"\n",
    "normalize = bool(manifest[\"embedding_config\"][\"text\"].get(\"normalize\", True))\n",
    "max_tokens   = int(manifest[\"embedding_config\"][\"text\"][\"chunking\"][\"max_tokens\"])\n",
    "overlap_toks = int(manifest[\"embedding_config\"][\"text\"][\"chunking\"][\"overlap_tokens\"])\n",
    "\n",
    "# Resolve precomputed index paths from manifest\n",
    "text_idx_cfg   = manifest[\"precomputed_indices\"][\"text\"]\n",
    "embeddings_path = ROOT / text_idx_cfg[\"embeddings\"]                  # \"vector_db/text/embeddings.jsonl\"\n",
    "meta_path       = ROOT / text_idx_cfg[\"meta\"]                        # \"vector_db/text/meta.json\"\n",
    "faiss_dir       = ROOT / text_idx_cfg[\"faiss\"][\"dir\"]                # \"vector_db/text/faiss_index\"\n",
    "faiss_index_path    = ROOT / text_idx_cfg[\"faiss\"][\"index\"]          # \".../index.faiss\"\n",
    "faiss_docstore_path = ROOT / text_idx_cfg[\"faiss\"][\"docstore\"]       # \".../index.pkl\"\n",
    "\n",
    "faiss_dir.mkdir(parents=True, exist_ok=True)\n",
    "embeddings_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "meta_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Using FAISS dir:\", faiss_dir)\n",
    "print(\"Embeddings JSONL:\", embeddings_path)\n",
    "print(\"Meta JSON:\", meta_path)\n",
    "\n",
    "# ---------- 1) Embeddings & chunking ----------\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Local Ollama embeddings (granite)\n",
    "emb = OllamaEmbeddings(model=embed_model_name)\n",
    "\n",
    "# Approx \"semantic+fixed\": sentence/para-ish splits → fixed window with overlap\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"। \", \". \", \"?\", \"!\", \" \"],\n",
    "    chunk_size=2000,          # character proxy for ~512 tokens; tune as needed\n",
    "    chunk_overlap=250,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "# ---------- 2) Build LangChain Documents with rich metadata ----------\n",
    "docs: List[Document] = []\n",
    "pack_name    = manifest[\"name\"]\n",
    "pack_ver     = manifest[\"version\"]\n",
    "pack_locales = manifest[\"locales\"]\n",
    "\n",
    "# citation id -> full object\n",
    "citations = {c[\"id\"]: c for c in manifest.get(\"citations\", [])}\n",
    "\n",
    "for topic in manifest[\"index_of_topics\"]:\n",
    "    topic_id = topic[\"id\"]\n",
    "    for fmeta in topic[\"core_files\"]:\n",
    "        fpath = ROOT / fmeta[\"path\"]\n",
    "        if not fpath.exists():\n",
    "            print(\"! Skipping missing file:\", fpath)\n",
    "            continue\n",
    "        raw = fpath.read_text(encoding=\"utf-8\")\n",
    "        chunks = splitter.split_text(raw)\n",
    "\n",
    "        # crude locale detection from path (hi_en folder)\n",
    "        locale = \"hi_en\" if \"/hi_en/\" in fmeta[\"path\"] else \"en\"\n",
    "\n",
    "        # expand citations\n",
    "        c_full = [citations[cid] for cid in fmeta.get(\"citations\", []) if cid in citations]\n",
    "\n",
    "        for i, text in enumerate(chunks):\n",
    "            docs.append(Document(\n",
    "                page_content=text,\n",
    "                metadata={\n",
    "                    \"pack_name\": pack_name,\n",
    "                    \"pack_version\": pack_ver,\n",
    "                    \"topic_id\": topic_id,\n",
    "                    \"file_id\": fmeta[\"id\"],\n",
    "                    \"path\": str(fmeta[\"path\"]),\n",
    "                    \"media_type\": fmeta[\"media_type\"],\n",
    "                    \"locale\": locale,\n",
    "                    \"citations\": c_full,\n",
    "                    \"chunk_index\": i,\n",
    "                    \"chunk_id\": f\"{fmeta['id']}::chunk::{i}\",\n",
    "                }\n",
    "            ))\n",
    "\n",
    "print(f\"Prepared {len(docs)} chunks\")\n",
    "\n",
    "# ---------- 3) Create FAISS & persist (no extra copies) ----------\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vs = FAISS.from_documents(docs, emb)\n",
    "vs.save_local(str(faiss_dir))  # writes index.faiss + index.pkl (overwrites if they exist)\n",
    "\n",
    "# sanity check\n",
    "assert faiss_index_path.exists(), f\"Missing {faiss_index_path}\"\n",
    "assert faiss_docstore_path.exists(), f\"Missing {faiss_docstore_path}\"\n",
    "print(\"FAISS artifacts saved ✅\", faiss_index_path.name, \"&\", faiss_docstore_path.name)\n",
    "\n",
    "# ---------- 4) Export JSONL embeddings + meta (portable) ----------\n",
    "# Note: this re-embeds each chunk for JSONL output. For big corpora, cache vectors during creation.\n",
    "records = []\n",
    "# Access the docstore that FAISS is holding (doc_id -> Document)\n",
    "doc_items = getattr(vs.docstore, \"_dict\", {})  # internal but commonly used\n",
    "\n",
    "for doc_id, doc in doc_items.items():\n",
    "    vec = emb.embed_query(doc.page_content)  # 768-dim for granite-embedding:278m\n",
    "    rec = {\n",
    "        \"id\": doc_id,\n",
    "        \"embedding\": vec,\n",
    "        \"metadata\": doc.metadata,\n",
    "        \"text\": doc.page_content\n",
    "    }\n",
    "    records.append(rec)\n",
    "\n",
    "with open(embeddings_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for r in records:\n",
    "        f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"model\": embed_model_name,\n",
    "        \"dim\": manifest[\"embedding_config\"][\"text\"][\"dim\"],\n",
    "        \"normalize\": normalize,\n",
    "        \"count\": len(records),\n",
    "        \"pack\": {\"name\": pack_name, \"version\": pack_ver, \"locales\": pack_locales}\n",
    "    }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"JSONL/meta saved ✅\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1158dcd9",
   "metadata": {},
   "source": [
    "### Testing it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad040d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='# Severe Bleeding Control\n",
      "Severe bleeding can quickly become life-threatening if not controlled.  \n",
      "Apply firm direct pressure with a clean cloth or sterile gauze.  \n",
      "If bleeding soaks through, add more cloths without removing the first.  \n",
      "Elevate the injured limb if possible while maintaining pressure.  \n",
      "Use a tourniquet if direct pressure fails and bleeding is from an arm or leg.  \n",
      "Note the time a tourniquet is applied and do not remove it until in a hospital.  \n",
      "Check the person’s airway, breathing, and circulation while giving first aid.  \n",
      "Reassure the patient and keep them warm to prevent shock.  \n",
      "Transport urgently to the nearest medical facility if bleeding does not stop.  \n",
      "Do not apply mud, ash, or unclean materials to the wound.' metadata={'pack_name': 'Eastern Bihar – First Aid & Community Health | पूर्वी बिहार – प्राथमिक चिकित्सा', 'pack_version': '0.3.1', 'topic_id': 'bleed-control', 'file_id': 'guide-bleed-overview', 'path': 'core/bleed-control/hi_en/bleeding_control_overview.md', 'media_type': 'text/markdown', 'locale': 'hi_en', 'citations': [{'id': 'who-bec', 'title': 'WHO Basic Emergency Care (B.E.C.)', 'url': 'https://www.who.int/emergencycare/publications/basic-emergency-care', 'license': 'CC BY-NC-SA (verify)'}], 'chunk_index': 0, 'chunk_id': 'guide-bleed-overview::chunk::0'}\n",
      "\n",
      "[1]\n",
      "Topic: bleed-control\n",
      "File: guide-bleed-overview\n",
      "Locale: hi_en\n",
      "Citations: ['WHO Basic Emergency Care (B.E.C.)']\n",
      "Chunk text:\n",
      "# Severe Bleeding Control\n",
      "Severe bleeding can quickly become life-threatening if not controlled.  \n",
      "Apply firm direct pressure with a clean cloth or sterile gauze.  \n",
      "If bleeding soaks through, add more cloths without removing the first.  \n",
      "Elevate the injured limb if possible while maintaining pressur ...\n",
      "page_content='# Flood-Related Wounds & Infection\n",
      "Flood water often carries dirt, sewage, and harmful bacteria.  \n",
      "Clean all cuts and wounds immediately with clean running water and soap.  \n",
      "Apply antiseptic if available and cover with a clean dressing.  \n",
      "Change dressings daily or if they become wet or dirty.  \n",
      "Watch for signs of infection: redness, swelling, pus, fever.  \n",
      "Ensure tetanus vaccination is up to date after flood injuries.  \n",
      "Avoid walking barefoot in flood waters to reduce risk of infection.  \n",
      "Do not apply mud, herbs, or dirty cloths to wounds.  \n",
      "Seek medical care if fever, spreading redness, or severe pain develops.  \n",
      "Support community cleanup of flood debris to reduce injury risk.' metadata={'pack_name': 'Eastern Bihar – First Aid & Community Health | पूर्वी बिहार – प्राथमिक चिकित्सा', 'pack_version': '0.3.1', 'topic_id': 'flood-wounds', 'file_id': 'guide-flood-infection', 'path': 'core/flood-wounds/hi_en/flood_infection_signs.md', 'media_type': 'text/markdown', 'locale': 'hi_en', 'citations': [{'id': 'icmr-lepto', 'title': 'ICMR – Leptospirosis Guidelines', 'url': 'https://main.icmr.nic.in', 'license': 'Open access; verify'}], 'chunk_index': 0, 'chunk_id': 'guide-flood-infection::chunk::0'}\n",
      "\n",
      "[2]\n",
      "Topic: flood-wounds\n",
      "File: guide-flood-infection\n",
      "Locale: hi_en\n",
      "Citations: ['ICMR – Leptospirosis Guidelines']\n",
      "Chunk text:\n",
      "# Flood-Related Wounds & Infection\n",
      "Flood water often carries dirt, sewage, and harmful bacteria.  \n",
      "Clean all cuts and wounds immediately with clean running water and soap.  \n",
      "Apply antiseptic if available and cover with a clean dressing.  \n",
      "Change dressings daily or if they become wet or dirty.  \n",
      "Watc ...\n",
      "page_content='# Snakebite\n",
      "Keep the patient calm and lying still to slow the spread of venom.  \n",
      "Remove rings, bangles, or tight clothing from the bitten limb.  \n",
      "Immobilize the limb with a splint and keep it at heart level.  \n",
      "Do not cut, suck, burn, or apply ice to the bite.  \n",
      "Do not apply tight tourniquets; they can cause more harm.  \n",
      "Transport the patient quickly and safely to the nearest hospital with antivenom.  \n",
      "Try to note the snake’s appearance but do not waste time capturing it.  \n",
      "Reassure the patient and discourage walking or running.  \n",
      "Record the time of the bite and any first aid given.  \n",
      "Look for warning signs such as drooping eyelids, difficulty breathing, or uncontrolled bleeding.' metadata={'pack_name': 'Eastern Bihar – First Aid & Community Health | पूर्वी बिहार – प्राथमिक चिकित्सा', 'pack_version': '0.3.1', 'topic_id': 'snakebite', 'file_id': 'guide-snakebite-donts', 'path': 'core/snakebite/hi_en/snakebite_dos_and_donts.md', 'media_type': 'text/markdown', 'locale': 'hi_en', 'citations': [{'id': 'who-searo-snakebite', 'title': 'WHO SEARO – Snakebite Management', 'url': 'https://www.who.int/searo', 'license': 'Open access; verify'}], 'chunk_index': 0, 'chunk_id': 'guide-snakebite-donts::chunk::0'}\n",
      "\n",
      "[3]\n",
      "Topic: snakebite\n",
      "File: guide-snakebite-donts\n",
      "Locale: hi_en\n",
      "Citations: ['WHO SEARO – Snakebite Management']\n",
      "Chunk text:\n",
      "# Snakebite\n",
      "Keep the patient calm and lying still to slow the spread of venom.  \n",
      "Remove rings, bangles, or tight clothing from the bitten limb.  \n",
      "Immobilize the limb with a splint and keep it at heart level.  \n",
      "Do not cut, suck, burn, or apply ice to the bite.  \n",
      "Do not apply tight tourniquets; they c ...\n",
      "page_content='# Common Poisoning (Pesticides)\n",
      "Accidental poisoning is common in rural areas due to unsafe pesticide storage.  \n",
      "Keep all chemicals in labeled, closed containers away from children.  \n",
      "If ingestion occurs, do not induce vomiting.  \n",
      "Remove contaminated clothing and wash skin with soap and water.  \n",
      "If chemicals contact eyes, rinse with plenty of clean water.  \n",
      "Take the container or label to the health facility if possible.  \n",
      "Supportive care and antidotes may be available in hospitals.  \n",
      "Watch for warning signs: excessive drooling, difficulty breathing, convulsions.  \n",
      "Do not give milk or home remedies without medical advice.  \n",
      "Promote safe storage and handling of chemicals in the community.' metadata={'pack_name': 'Eastern Bihar – First Aid & Community Health | पूर्वी बिहार – प्राथमिक चिकित्सा', 'pack_version': '0.3.1', 'topic_id': 'poisoning', 'file_id': 'guide-poison-firstaid', 'path': 'core/poisoning/hi_en/poisoning_first_aid.md', 'media_type': 'text/markdown', 'locale': 'hi_en', 'citations': [{'id': 'who-bec', 'title': 'WHO Basic Emergency Care (B.E.C.)', 'url': 'https://www.who.int/emergencycare/publications/basic-emergency-care', 'license': 'CC BY-NC-SA (verify)'}], 'chunk_index': 0, 'chunk_id': 'guide-poison-firstaid::chunk::0'}\n",
      "\n",
      "[4]\n",
      "Topic: poisoning\n",
      "File: guide-poison-firstaid\n",
      "Locale: hi_en\n",
      "Citations: ['WHO Basic Emergency Care (B.E.C.)']\n",
      "Chunk text:\n",
      "# Common Poisoning (Pesticides)\n",
      "Accidental poisoning is common in rural areas due to unsafe pesticide storage.  \n",
      "Keep all chemicals in labeled, closed containers away from children.  \n",
      "If ingestion occurs, do not induce vomiting.  \n",
      "Remove contaminated clothing and wash skin with soap and water.  \n",
      "If  ...\n"
     ]
    }
   ],
   "source": [
    "# Typical retriever usage\n",
    "retriever = vs.as_retriever(search_kwargs={\"k\": 4})  # if you used Option A 'vs'\n",
    "query = \"What to do for bleeding?\"  #\n",
    "hits = retriever.invoke(query)\n",
    "\n",
    "for i, d in enumerate(hits, 1):\n",
    "    print(d)\n",
    "    print(f\"\\n[{i}]\")\n",
    "    print(\"Topic:\", d.metadata[\"topic_id\"])\n",
    "    print(\"File:\", d.metadata[\"file_id\"])\n",
    "    print(\"Locale:\", d.metadata[\"locale\"])\n",
    "    print(\"Citations:\", [c[\"title\"] for c in d.metadata.get(\"citations\", [])])\n",
    "    print(\"Chunk text:\")\n",
    "    print(d.page_content[:300], \"...\" if len(d.page_content) > 300 else \"\")\n",
    "\n",
    "# Filter to a topic or locale:\n",
    "hits = retriever.invoke(\"tourniquet steps\", filter={\"topic_id\": \"bleed-control\", \"locale\": \"en\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbe1544",
   "metadata": {},
   "source": [
    ":)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0609f501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
