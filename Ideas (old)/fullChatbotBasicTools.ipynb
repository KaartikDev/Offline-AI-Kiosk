{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c03167",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "\n",
    "This notebook goes beyond context() tools.\n",
    "\n",
    "\n",
    "#### context(query, top_k=5)\n",
    "- Searches the core knowledge pack’s vector database of text chunks.  \n",
    "- Returns the top matching snippets with IDs, text, and relevance scores.  \n",
    "- **Purpose:** retrieve authoritative guidance from curated docs.  \n",
    "\n",
    "#### getImage(query)\n",
    "- Searches an image-caption vector database for diagrams/photos relevant to the query.  \n",
    "- Displays likley image with captions and file paths.  \n",
    "- **Purpose:** give visual reinforcement (e.g., bandage diagrams, water purification images).  \n",
    "\n",
    "#### knowledgeMeta()\n",
    "- Reads pack metadata (from a manifest file).  \n",
    "- Returns the current version and last-updated date of the knowledge pack.  \n",
    "- **Purpose:** build trust by showing how recent and reliable the knowledge is.  \n",
    "\n",
    "\n",
    "#### math tools: multiply, add, subtract, divide  \n",
    "- **Purpose:** do math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6a332a",
   "metadata": {},
   "source": [
    "###  Setting up paths and loading vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d166f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 0) Imports & manifest ===\n",
    "from pathlib import Path\n",
    "import yaml, json\n",
    "from typing import Optional, List, Dict\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.tools import tool\n",
    "from langchain.schema import Document\n",
    "\n",
    "# If you want the prebuilt ReAct agent:\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# If you prefer to also expose tools directly on the LLM:\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# --- Set your pack root + manifest ---\n",
    "ROOT = Path(\"/Users/ktejwani/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/first_aid_pack_demo_v2\")\n",
    "MANIFEST = ROOT / \"manifest.yaml\"\n",
    "\n",
    "with open(MANIFEST, \"r\", encoding=\"utf-8\") as f:\n",
    "    manifest = yaml.safe_load(f)\n",
    "\n",
    "# --- Resolve FAISS paths from manifest ---\n",
    "faiss_dir_text = ROOT / manifest[\"precomputed_indices\"][\"text\"][\"faiss\"][\"dir\"]\n",
    "faiss_dir_image = ROOT / manifest[\"precomputed_indices\"][\"images\"][\"faiss\"][\"dir\"]\n",
    "# --- Create embeddings *matching the store* ---\n",
    "embed_model_name = manifest[\"embedding_config\"][\"text\"][\"model\"]     #same for text and image\n",
    "emb = OllamaEmbeddings(model=embed_model_name)\n",
    "\n",
    "# --- Load FAISS store + retriever ---\n",
    "text_vs = FAISS.load_local(str(faiss_dir_text), emb, allow_dangerous_deserialization=True)\n",
    "text_retriever = text_vs.as_retriever(search_kwargs={\"k\": 4})  # default k; tool will override if provided\n",
    "\n",
    "image_vs = FAISS.load_local(str(faiss_dir_image), emb, allow_dangerous_deserialization=True)\n",
    "# results = image_vs.similarity_search_with_score(query, k=4)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93926748",
   "metadata": {},
   "source": [
    "### Defining helper and context() Tool  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a18ea3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1) Helpers ===\n",
    "def format_chunk(doc: Document, max_chars: int = 400) -> Dict:\n",
    "    \"\"\"Return a dict with compact text + key metadata for prompting & audit.\"\"\"\n",
    "    txt = doc.page_content.strip()\n",
    "    if len(txt) > max_chars:\n",
    "        txt = txt[:max_chars].rstrip() + \" …\"\n",
    "    m = doc.metadata\n",
    "    return {\n",
    "        \"id\": m.get(\"chunk_id\"),\n",
    "        \"topic_id\": m.get(\"topic_id\"),\n",
    "        \"file_id\": m.get(\"file_id\"),\n",
    "        \"locale\": m.get(\"locale\"),\n",
    "        \"path\": m.get(\"path\"),\n",
    "        \"citations\": [c.get(\"title\", \"\") for c in m.get(\"citations\", [])],\n",
    "        \"text\": txt\n",
    "    }\n",
    "\n",
    "def format_context_block(chunks: List[Dict]) -> str:\n",
    "    \"\"\"Human/LLM-friendly context block the agent can drop into its reasoning.\"\"\"\n",
    "    lines = []\n",
    "    lines.append(\"### Retrieved Context (use only what is relevant)\")\n",
    "    for i, c in enumerate(chunks, 1):\n",
    "        cite_str = \"; \".join([t for t in c[\"citations\"] if t]) or \"—\"\n",
    "        head = f\"[{i}] {c['topic_id']} · {c['file_id']} · {c['locale']} · {c['path']}\"\n",
    "        lines.append(head)\n",
    "        lines.append(c[\"text\"])\n",
    "        lines.append(f\"Source(s): {cite_str}\")\n",
    "        lines.append(\"\")  # blank line\n",
    "    return \"\\n\".join(lines).strip()\n",
    "\n",
    "\n",
    "# === 2) The @tool: context() ===\n",
    "@tool\n",
    "def context(\n",
    "    query: str,\n",
    "    k: int = 4,\n",
    "    topic_id: Optional[str] = None,\n",
    "    locale: Optional[str] = None\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve up to k relevant knowledge-pack chunks for 'query' and return a formatted\n",
    "    context block + structured per-chunk data for citations. You must use this tool for any prompt that is \n",
    "    important to wellbeing or safety of user. \n",
    "\n",
    "    Args:\n",
    "        query: Natural language question or keywords.\n",
    "        k: Top-k chunks to return (default 4).\n",
    "        topic_id: Optional manifest topic filter (e.g., 'bleed-control').\n",
    "        locale: Optional locale filter (e.g., 'hi_en' or 'en').\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "          \"query\": str,\n",
    "          \"k\": int,\n",
    "          \"filters\": {\"topic_id\":..., \"locale\":...},\n",
    "          \"context_block\": str,     # pasteable into prompts\n",
    "          \"chunks\": [ {id, topic_id, file_id, path, locale, citations[], text}, ... ]\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Build a metadata filter if provided\n",
    "    _filter = {}\n",
    "    # if topic_id:\n",
    "    #     _filter[\"topic_id\"] = topic_id\n",
    "    # if locale:\n",
    "    #     _filter[\"locale\"] = locale\n",
    "\n",
    "    # Run retrieval (override k)\n",
    "    local_ret = text_vs.as_retriever(search_kwargs={\"k\": k})\n",
    "    hits: List[Document] = local_ret.invoke(query) if not _filter else local_ret.invoke(query, filter=_filter)\n",
    "\n",
    "    formatted = [format_chunk(d) for d in hits]\n",
    "    ctx_block = format_context_block(formatted)\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"k\": k,\n",
    "        \"filters\": _filter,\n",
    "        \"context_block\": ctx_block,\n",
    "        \"chunks\": formatted\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f80b651",
   "metadata": {},
   "source": [
    "### Math Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fbe93eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers.\n",
    "    \n",
    "    Args:\n",
    "        a: First float\n",
    "        b: Second float\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def subtract(a: float, b: float) -> float:\n",
    "    \"\"\"Subtract first number by second number.\n",
    "\n",
    "    Args:\n",
    "        a: First float\n",
    "        b: Second float\n",
    "    \"\"\"\n",
    "    return a - b\n",
    "\n",
    "@tool\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers.\n",
    "\n",
    "    Args:\n",
    "        a: First float\n",
    "        b: Second float\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def divide(a : float, b: float) -> float:\n",
    "    \"\"\"Divide first number by second number.\n",
    "    \n",
    "    Args:\n",
    "        a: First float\n",
    "        b: Second float\n",
    "    \"\"\"\n",
    "    if b == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return a/b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69135961",
   "metadata": {},
   "source": [
    "### Defining knowledgeMeta() tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b002ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from typing import Optional\n",
    "\n",
    "@tool\n",
    "def knowledgeMeta(pack_dir: Optional[str] = None) -> dict:\n",
    "    \"\"\"\n",
    "    Read a knowledge pack manifest and return metadata for trust and recency. \n",
    "\n",
    "    Args:\n",
    "      pack_dir: Absolute or relative path to the pack folder (containing manifest.yaml).\n",
    "                If omitted, uses the default ROOT pack path.\n",
    "\n",
    "    Returns:\n",
    "      {\n",
    "        \"name\": str,\n",
    "        \"version\": str,\n",
    "        \"date\": str,\n",
    "        \"locales\": [..],\n",
    "        \"topics_count\": int,\n",
    "        \"manifest_path\": str\n",
    "      }\n",
    "    \"\"\"\n",
    "    # default to your earlier ROOT if not provided\n",
    "    base = Path(pack_dir) if pack_dir else ROOT\n",
    "    manifest_path = base / \"manifest.yaml\"\n",
    "    if not manifest_path.exists():\n",
    "        return {\"error\": f\"manifest.yaml not found at {manifest_path}\"}\n",
    "\n",
    "    with open(manifest_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        m = yaml.safe_load(f)\n",
    "\n",
    "    name = m.get(\"name\", str(base.name))\n",
    "    version = m.get(\"version\", \"unknown\")\n",
    "    date = m.get(\"date\", \"unknown\")\n",
    "    locales = m.get(\"locales\", [])\n",
    "    topics = m.get(\"index_of_topics\", []) or []\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"version\": version,\n",
    "        \"date\": date,\n",
    "        \"locales\": locales,\n",
    "        \"topics_count\": len(topics),\n",
    "        \"manifest_path\": str(manifest_path)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b781c4fc",
   "metadata": {},
   "source": [
    "### getImage tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1d162578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "\n",
    "HIGH_SCORE_THRESHOLD = 0.55  # tune as needed\n",
    "\n",
    "@tool\n",
    "def getImage(query: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Retrieve and display exactly one image for the user's query.\n",
    "    Applies a high-confidence threshold; returns NO_IMAGE if nothing clears the bar.\n",
    "    \"\"\"\n",
    "    q = (query or \"\").strip()\n",
    "    pack_name    = manifest.get(\"name\", \"\")\n",
    "    pack_ver     = manifest.get(\"version\", \"\")\n",
    "    pack_date    = manifest.get(\"date\", \"\")\n",
    "    pack_locales = manifest.get(\"locales\", [])\n",
    "\n",
    "    if not q:\n",
    "        return {\n",
    "            \"status\": \"NO_IMAGE\",\n",
    "            \"version\": pack_ver,\n",
    "            \"date\": pack_date,\n",
    "            \"locales\": pack_locales,\n",
    "            \"pack_name\": pack_name,\n",
    "            \"image_path\": \"\",\n",
    "            \"score\": None,\n",
    "            \"citations\": []\n",
    "        }\n",
    "\n",
    "    # Use similarity_search_with_score to get confidence scores\n",
    "    foundImage = False\n",
    "    minScore = 0.32\n",
    "    finalDoc  = Document(page_content=\"\")\n",
    "    results = image_vs.similarity_search_with_score(query, k=4)\n",
    "    finScore = 0\n",
    "    from IPython.display import Image, display\n",
    "\n",
    "    for i, (d, score) in enumerate(results, 1):\n",
    "        \n",
    "        if score >= minScore:\n",
    "            finScore = score\n",
    "            finalDoc = d\n",
    "            foundImage = True\n",
    "            break\n",
    "    \n",
    "\n",
    "    if not foundImage:\n",
    "        print(\"NOT FOUND\")\n",
    "        return {\n",
    "            \"status\": \"NO_IMAGE\",\n",
    "            \"version\": pack_ver,\n",
    "            \"date\": pack_date,\n",
    "            \"locales\": pack_locales,\n",
    "            \"pack_name\": pack_name,\n",
    "            \"image_path\": \"\",\n",
    "            \"score\": None,\n",
    "            \"citations\": []\n",
    "        }\n",
    "    else:\n",
    "        print(\"Found FOUND\")\n",
    "        img_path = ROOT / finalDoc.metadata['path']\n",
    "        # try:\n",
    "        #     display(Image(filename=img_path))\n",
    "        # except Exception:\n",
    "        #     pass\n",
    "            \n",
    "        return {\n",
    "            \"status\": \"OK\",\n",
    "            \"version\": pack_ver,\n",
    "            \"date\": pack_date,\n",
    "            \"locales\": pack_locales,\n",
    "            \"pack_name\": pack_name,\n",
    "            \"image_path\": str(img_path),\n",
    "            \"score\": float(finScore),\n",
    "            \"citations\": finalDoc.metadata.get(\"citations\", [])\n",
    "        }\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad48bd",
   "metadata": {},
   "source": [
    "### List of Available Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "14c9825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a Tools list for whichever orchestration you choose:\n",
    "TOOLS = [context,add,multiply,subtract,divide,knowledgeMeta, getImage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd22fb2c",
   "metadata": {},
   "source": [
    "### Setting Up LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "14a99997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model=\"ollama:gpt-oss:20b\",       \n",
    "    temperature=0.2  # lower = more deterministic\n",
    ")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(TOOLS) #llm_with_tools is a new wrapped llm\n",
    "model = llm_with_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d161dfa",
   "metadata": {},
   "source": [
    "### Testing Tool Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e467a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.messages import HumanMessage\n",
    "# #message classes on lang chain inlcude human massage ,ai message, system message, and tool message\n",
    "# query = \"call get image to show torniquet on leg\"\n",
    "\n",
    "# messages = [HumanMessage(query)]\n",
    "\n",
    "# ai_msg = llm_with_tools.invoke(messages) #llm_with_tools looks at history(currently only 1 human message) and then builds prompt\n",
    "# print(\"AI MESSAEGE CALLS\")\n",
    "# print(ai_msg)\n",
    "# print(\"JUST AI TOOL CALLS\")\n",
    "# print(ai_msg.tool_calls) \n",
    "# #Now we add the bots message to the chat history\n",
    "# messages.append(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f3d18ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tool_call in ai_msg.tool_calls: #Actually running all the tool calls ai requested in last cell\n",
    "#     tools_dict = {\"context\": context, \"knowledgeMeta\":knowledgeMeta,\"add\":add,\n",
    "#             \"subtract\":subtract,\"divide\":divide,\"multiply\":multiply, \"getImage\":getImage}\n",
    "#     selected_tool = tools_dict[tool_call[\"name\"]]\n",
    "#     tool_msg = selected_tool.invoke(tool_call)\n",
    "#     messages.append(tool_msg) #Add the tool message to chat history\n",
    "\n",
    "# messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b0bf28",
   "metadata": {},
   "source": [
    "### Reason - Act Agent Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "450b94f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (\n",
    "    Annotated, #Extra metadata\n",
    "    Sequence, #generic list container\n",
    "    TypedDict, #Lets you define a dictionary type with fixed keys and types\n",
    ") #a dictionary type has a specific format of what key and valye types can be \n",
    "from langchain_core.messages import BaseMessage #lang chain message format (Human,Systen,AI)\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"The state of the agent.\"\"\"\n",
    "\n",
    "    # add_messages is a reducer\n",
    "    # See https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "#define a state dictionary, 1 key names messages\n",
    "#messages is a list of langchain base messages\n",
    "#wrapping it in Annotated tells it to not replace entire list but use add_messages to merge it in\n",
    "#The accepected value  for this dictionary will be Sequence[BaseMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad07e24e",
   "metadata": {},
   "source": [
    "### Defining nodes and edges in \"Lang graph\"\n",
    "\n",
    "Lang graph:\n",
    "- Imagine you're in a big construction truck and you have a map of stops\n",
    "- Each stop pick up something/do a \n",
    "- Folow the street signs to get to all the stops\n",
    "- Take a photo to save state during important jobs\n",
    "\n",
    "The big truck carries chat histroy. The road signs are edges between nodes where nodes are the stops. The photos are state changes you can reload to(checkpoint in video game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d1e467c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage, SystemMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "tools_dict = {\"context\": context, \"knowledgeMeta\":knowledgeMeta,\"add\":add,\n",
    "            \"subtract\":subtract,\"divide\":divide,\"multiply\":multiply, \"getImage\":getImage}\n",
    "\n",
    "tools_by_name = tools_dict\n",
    "\n",
    "\n",
    "# Define our tool node\n",
    "def tool_node(state: AgentState): #Agent State is the conversation history\n",
    "    outputs = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls: #Look at the last message in history(should be AIMessage)\n",
    "        tool_result = tools_by_name[tool_call[\"name\"]].invoke(tool_call[\"args\"]) #Actually call the tool\n",
    "        outputs.append( #Add a json output to conco hsitory\n",
    "            ToolMessage(\n",
    "                content=json.dumps(tool_result),\n",
    "                name=tool_call[\"name\"],\n",
    "                tool_call_id=tool_call[\"id\"],\n",
    "            )\n",
    "        )\n",
    "    return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "# Define the node that calls the model\n",
    "def call_model(\n",
    "    state: AgentState,\n",
    "    config: RunnableConfig,\n",
    "):\n",
    "    temp_system_str = \"For ANY health or safety query, you MUST call the `context` tool.  Do not answer from memory.\"\n",
    "    # this is similar to customizing the create_react_agent with 'prompt' parameter, but is more flexible\n",
    "    system_prompt = SystemMessage(\n",
    "        \"You are a helpful AI assistant, please respond to the users query to the best of your ability!\" + temp_system_str\n",
    "    )\n",
    "    response = model.invoke([system_prompt] + state[\"messages\"], config)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Define the conditional edge that determines whether to continue or not\n",
    "def should_continue(state: AgentState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0745cd75",
   "metadata": {},
   "source": [
    "### Defining new Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b94e222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'Exception'>\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings, and the values are other nodes.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"tools\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Now we can compile and visualize our graph\n",
    "graph = workflow.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is \n",
    "    print(Exception)\n",
    "    pass\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47485d2b",
   "metadata": {},
   "source": [
    "### Print output stream function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7dcb80ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for formatting the stream nicely\n",
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        prev_msg = \"\"\n",
    "        if len(s['messages']) > 1:\n",
    "            prev_msg = s[\"messages\"][-2]\n",
    "\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "        # if prev_msg != \"\":\n",
    "        #     if isinstance(prev_msg, tuple):\n",
    "        #         print(prev_msg)\n",
    "        #     else:\n",
    "        #         prev_msg.pretty_print()\n",
    "\n",
    "\n",
    "# inputs = {\"messages\": [(\"user\", \"What to do if bleed? When Knowledge updated? What 42*321 and 32/31?\")]}\n",
    "# print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313cd475",
   "metadata": {},
   "source": [
    "### Infinte Loop Chat Bot\n",
    "\n",
    "After eahc exit please restart kernel and clear all outputs to ensure a fresh conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f493ab70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type a message. Commands: /reset, /exit\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Show me tourniquet\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  context (26db9748-dc5b-4dfb-a42c-c50d694b8948)\n",
      " Call ID: 26db9748-dc5b-4dfb-a42c-c50d694b8948\n",
      "  Args:\n",
      "    k: 4\n",
      "    locale: en\n",
      "    query: tourniquet\n",
      "    topic_id: None\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: context\n",
      "\n",
      "{\"query\": \"tourniquet\", \"k\": 4, \"filters\": {}, \"context_block\": \"### Retrieved Context (use only what is relevant)\\n[1] bleed-control \\u00b7 guide-bleed-overview \\u00b7 hi_en \\u00b7 core/bleed-control/hi_en/bleeding_control_overview.md\\n# Severe Bleeding Control\\nSevere bleeding can quickly become life-threatening if not controlled.  \\nApply firm direct pressure with a clean cloth or sterile gauze.  \\nIf bleeding soaks through, add more cloths without removing the first.  \\nElevate the injured limb if possible while maintaining pressure.  \\nUse a tourniquet if direct pressure fails and bleeding is from an arm or leg.  \\nNote the time a \\u2026\\nSource(s): WHO Basic Emergency Care (B.E.C.)\\n\\n[2] snakebite \\u00b7 guide-snakebite-donts \\u00b7 hi_en \\u00b7 core/snakebite/hi_en/snakebite_dos_and_donts.md\\n# Snakebite\\nKeep the patient calm and lying still to slow the spread of venom.  \\nRemove rings, bangles, or tight clothing from the bitten limb.  \\nImmobilize the limb with a splint and keep it at heart level.  \\nDo not cut, suck, burn, or apply ice to the bite.  \\nDo not apply tight tourniquets; they can cause more harm.  \\nTransport the patient quickly and safely to the nearest hospital with antiveno \\u2026\\nSource(s): WHO SEARO \\u2013 Snakebite Management\\n\\n[3] fracture-splint \\u00b7 guide-fracture-overview \\u00b7 hi_en \\u00b7 core/fracture-splint/hi_en/fracture_overview.md\\n# Fracture & Splinting\\nFractures may present with pain, swelling, deformity, and inability to use the limb.  \\nImmobilize the joint above and below the suspected fracture.  \\nUse local materials such as bamboo sticks, boards, or rolled newspapers as splints.  \\nPad the splints with cloth before tying them in place.  \\nAvoid moving the broken bone excessively while applying the splint.  \\nCheck circulat \\u2026\\nSource(s): WHO Basic Emergency Care (B.E.C.)\\n\\n[4] choking \\u00b7 guide-choking-adult \\u00b7 hi_en \\u00b7 core/choking/hi_en/choking_adult.md\\n# Choking (Adult/Child/Infant)\\nChoking occurs when an object blocks the airway.  \\nAdults and children who cannot cough or speak need immediate help.  \\nPerform abdominal thrusts (Heimlich maneuver) for adults and older children.  \\nFor infants under 1 year, give 5 back blows followed by 5 chest thrusts.  \\nDo not attempt blind finger sweeps in the mouth.  \\nIf the person becomes unresponsive, start CP \\u2026\\nSource(s): WHO Basic Emergency Care (B.E.C.)\", \"chunks\": [{\"id\": \"guide-bleed-overview::chunk::0\", \"topic_id\": \"bleed-control\", \"file_id\": \"guide-bleed-overview\", \"locale\": \"hi_en\", \"path\": \"core/bleed-control/hi_en/bleeding_control_overview.md\", \"citations\": [\"WHO Basic Emergency Care (B.E.C.)\"], \"text\": \"# Severe Bleeding Control\\nSevere bleeding can quickly become life-threatening if not controlled.  \\nApply firm direct pressure with a clean cloth or sterile gauze.  \\nIf bleeding soaks through, add more cloths without removing the first.  \\nElevate the injured limb if possible while maintaining pressure.  \\nUse a tourniquet if direct pressure fails and bleeding is from an arm or leg.  \\nNote the time a \\u2026\"}, {\"id\": \"guide-snakebite-donts::chunk::0\", \"topic_id\": \"snakebite\", \"file_id\": \"guide-snakebite-donts\", \"locale\": \"hi_en\", \"path\": \"core/snakebite/hi_en/snakebite_dos_and_donts.md\", \"citations\": [\"WHO SEARO \\u2013 Snakebite Management\"], \"text\": \"# Snakebite\\nKeep the patient calm and lying still to slow the spread of venom.  \\nRemove rings, bangles, or tight clothing from the bitten limb.  \\nImmobilize the limb with a splint and keep it at heart level.  \\nDo not cut, suck, burn, or apply ice to the bite.  \\nDo not apply tight tourniquets; they can cause more harm.  \\nTransport the patient quickly and safely to the nearest hospital with antiveno \\u2026\"}, {\"id\": \"guide-fracture-overview::chunk::0\", \"topic_id\": \"fracture-splint\", \"file_id\": \"guide-fracture-overview\", \"locale\": \"hi_en\", \"path\": \"core/fracture-splint/hi_en/fracture_overview.md\", \"citations\": [\"WHO Basic Emergency Care (B.E.C.)\"], \"text\": \"# Fracture & Splinting\\nFractures may present with pain, swelling, deformity, and inability to use the limb.  \\nImmobilize the joint above and below the suspected fracture.  \\nUse local materials such as bamboo sticks, boards, or rolled newspapers as splints.  \\nPad the splints with cloth before tying them in place.  \\nAvoid moving the broken bone excessively while applying the splint.  \\nCheck circulat \\u2026\"}, {\"id\": \"guide-choking-adult::chunk::0\", \"topic_id\": \"choking\", \"file_id\": \"guide-choking-adult\", \"locale\": \"hi_en\", \"path\": \"core/choking/hi_en/choking_adult.md\", \"citations\": [\"WHO Basic Emergency Care (B.E.C.)\"], \"text\": \"# Choking (Adult/Child/Infant)\\nChoking occurs when an object blocks the airway.  \\nAdults and children who cannot cough or speak need immediate help.  \\nPerform abdominal thrusts (Heimlich maneuver) for adults and older children.  \\nFor infants under 1 year, give 5 back blows followed by 5 chest thrusts.  \\nDo not attempt blind finger sweeps in the mouth.  \\nIf the person becomes unresponsive, start CP \\u2026\"}]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  getImage (4e3f1cc1-cab8-407d-bb7c-249d11afd5db)\n",
      " Call ID: 4e3f1cc1-cab8-407d-bb7c-249d11afd5db\n",
      "  Args:\n",
      "    query: tourniquet\n",
      "Found FOUND\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: getImage\n",
      "\n",
      "{\"status\": \"OK\", \"version\": \"0.3.1\", \"date\": \"2025-08-23\", \"locales\": [\"hi\", \"en\"], \"pack_name\": \"Eastern Bihar \\u2013 First Aid & Community Health | \\u092a\\u0942\\u0930\\u094d\\u0935\\u0940 \\u092c\\u093f\\u0939\\u093e\\u0930 \\u2013 \\u092a\\u094d\\u0930\\u093e\\u0925\\u092e\\u093f\\u0915 \\u091a\\u093f\\u0915\\u093f\\u0924\\u094d\\u0938\\u093e\", \"image_path\": \"/Users/ktejwani/Personal CS Projects/Summer 2025/Offline AI Kiosk/Offline-AI-Kiosk/first_aid_pack_demo_v2/assets/bleeding/tourniquet.png\", \"score\": 0.5874264240264893, \"citations\": [{\"id\": \"journal-trauma\", \"title\": \"Improvised tourniquets: Obsolete or obligatory?\", \"url\": \"https://www.researchgate.net/publication/270003434_Improvised_tourniquets_Obsolete_or_obligatory\", \"license\": \"NOT SURE\"}]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here’s a visual reference for a tourniquet, along with a quick reminder of when and how it’s used:\n",
      "\n",
      "---\n",
      "\n",
      "### Tourniquet Image\n",
      "![Tourniquet](file:///Users/ktejwani/Personal%20CS%20Projects/Summer%202025/Offline%20AI%20Kiosk/Offline-AI-Kiosk/first_aid_pack_demo_v2/assets/bleeding/tourniquet.png)\n",
      "\n",
      "*Image source: “Improvised tourniquets: Obsolete or obligatory?” – WHO Basic Emergency Care (B.E.C.) guidelines.*\n",
      "\n",
      "---\n",
      "\n",
      "### Quick Reference\n",
      "\n",
      "| Situation | When to Use | Key Steps |\n",
      "|-----------|-------------|-----------|\n",
      "| **Severe limb bleeding** (arm or leg) | If direct pressure fails to control bleeding | 1. **Apply** the tourniquet above the wound (closer to the body). <br>2. **Tighten** until bleeding stops. <br>3. **Mark** the time of application. <br>4. **Do not** remove until professional medical help arrives. |\n",
      "| **Field or remote settings** | When no other means of controlling bleeding are available | Use a **commercial or improvised** tourniquet that can be tightened quickly and reliably. |\n",
      "\n",
      "> **Important:**  \n",
      "> • Do **not** use a tourniquet for snakebite or other non‑bleeding injuries.  \n",
      "> • Keep the limb elevated if possible while maintaining pressure.  \n",
      "> • Monitor for signs of tissue damage (color change, numbness) and seek medical care promptly.\n",
      "\n",
      "---\n",
      "\n",
      "**Sources**\n",
      "\n",
      "- WHO Basic Emergency Care (B.E.C.) – Severe Bleeding Control guidelines.  \n",
      "- WHO SEARO – Snakebite Management (tourniquets are contraindicated for snakebite).  \n",
      "\n",
      "Feel free to let me know if you’d like more details on how to apply a tourniquet or other first‑aid steps!\n",
      "Found FOUND\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "/restart\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I’m ready to start over. How can I help you today?\n",
      "Bye!\n"
     ]
    }
   ],
   "source": [
    "# === Simple REPL loop for Jupyter ===\n",
    "def chat_loop():\n",
    "    history = []\n",
    "    print(\"Type a message. Commands: /reset, /exit\\n\")\n",
    "    while True:\n",
    "        user = input(\"You: \").strip()\n",
    "        if not user:\n",
    "            continue\n",
    "        if user.lower() in {\"/exit\", \"/quit\"}:\n",
    "            print(\"Bye!\")\n",
    "            break\n",
    "        if user.lower() == \"/reset\":\n",
    "            history = []\n",
    "            print(\"(conversation cleared)\")\n",
    "            continue\n",
    "\n",
    "        # Append user turn\n",
    "        inputs = {\"messages\": history + [(\"user\", user)]}\n",
    "\n",
    "        # Use YOUR print_stream exactly as written\n",
    "        print_stream(graph.stream(inputs, stream_mode=\"values\"))\n",
    "\n",
    "        # Capture updated history so context persists\n",
    "        final_state = graph.invoke(inputs)\n",
    "        history = final_state[\"messages\"]\n",
    "\n",
    "# Run this cell in your notebook to start chatting\n",
    "chat_loop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123ddfc1",
   "metadata": {},
   "source": [
    ":)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbff1846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded796d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
