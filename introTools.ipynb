{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fddc31e6",
   "metadata": {},
   "source": [
    "### Introduction \n",
    "\n",
    "Notebook explores how a LLM can call tools <br>\n",
    "https://python.langchain.com/docs/how_to/tool_results_pass_to_model/\n",
    "https://github.com/langchain-ai/langchain/blob/master/docs/docs/tutorials/agents.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aab550",
   "metadata": {},
   "source": [
    "### Setting Up Model\n",
    "\n",
    "Using llama3.1 for quick development purposed.\n",
    "Need to do ```ollama pull MODELNAME``` before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5672d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "# from langchain_tavily import TavilySearch\n",
    "# from langgraph.checkpoint.memory import MemorySaver\n",
    "# from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model=\"ollama:llama3.1\",        # or \"gpt-4o-mini\", \"ollama/llama3.1\", etc.\n",
    "    temperature=0.2  # lower = more deterministic\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf544914",
   "metadata": {},
   "source": [
    "### Defining Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a3c5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function name, type hints, and docstring are all part of the tool\n",
    "# schema that's passed to the model. Defining good, descriptive schemas\n",
    "# is an extension of prompt engineering and is an important part of\n",
    "# getting models to perform well.\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "#The decorator wraps in langchains type so it becomes runnable wiht .invoke(..)\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers.\n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers.\n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693c973c",
   "metadata": {},
   "source": [
    "### Testing: Can LLM see tools?\n",
    "\n",
    "LLM can not call tools in lang chain, only request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1245a30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-08-24T22:41:48.407425Z', 'done': True, 'done_reason': 'stop', 'total_duration': 13486425584, 'load_duration': 12192829334, 'prompt_eval_count': 254, 'prompt_eval_duration': 773944250, 'eval_count': 22, 'eval_duration': 518181209, 'model_name': 'llama3.1'}, id='run--db5e283e-d191-42ad-aa56-f52e4583c0b4-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'a56c326f-93cd-46be-a79a-207f27db586e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 254, 'output_tokens': 22, 'total_tokens': 276})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools(tools) #llm_with_tools is a new wrapped llm\n",
    "\n",
    "query = \"What is 3 * 12?\"\n",
    "\n",
    "llm_with_tools.invoke(query) #\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb5599a",
   "metadata": {},
   "source": [
    "### Full Agentic Tool Use by LLM\n",
    "\n",
    "Set up quick chat history and invoke model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f83645af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI MESSAEGE CALLS\n",
      "content='' additional_kwargs={} response_metadata={'model': 'llama3.1', 'created_at': '2025-08-24T22:41:49.622484Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1187052292, 'load_duration': 42706417, 'prompt_eval_count': 264, 'prompt_eval_duration': 102223542, 'eval_count': 43, 'eval_duration': 1041535375, 'model_name': 'llama3.1'} id='run--3f8d2bee-2aff-4a8d-a783-513efdaf68a7-0' tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'f09d3337-0574-4034-9d82-900b48ce1125', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': '3d89bbff-24d7-4032-b7b6-a4c12091d76f', 'type': 'tool_call'}] usage_metadata={'input_tokens': 264, 'output_tokens': 43, 'total_tokens': 307}\n",
      "JUST AI TOOL CALLS\n",
      "[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'f09d3337-0574-4034-9d82-900b48ce1125', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': '3d89bbff-24d7-4032-b7b6-a4c12091d76f', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "#message classes on lang chain inlcude human massage ,ai message, system message, and tool message\n",
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(messages) #llm_with_tools looks at history(currently only 1 human message) and then builds prompt\n",
    "print(\"AI MESSAEGE CALLS\")\n",
    "print(ai_msg)\n",
    "print(\"JUST AI TOOL CALLS\")\n",
    "print(ai_msg.tool_calls) \n",
    "#Now we add the bots message to the chat history\n",
    "messages.append(ai_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71155bf",
   "metadata": {},
   "source": [
    "#### Acually call the tools and give response back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65efba84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-08-24T22:41:49.622484Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1187052292, 'load_duration': 42706417, 'prompt_eval_count': 264, 'prompt_eval_duration': 102223542, 'eval_count': 43, 'eval_duration': 1041535375, 'model_name': 'llama3.1'}, id='run--3f8d2bee-2aff-4a8d-a783-513efdaf68a7-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'f09d3337-0574-4034-9d82-900b48ce1125', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': '3d89bbff-24d7-4032-b7b6-a4c12091d76f', 'type': 'tool_call'}], usage_metadata={'input_tokens': 264, 'output_tokens': 43, 'total_tokens': 307}),\n",
       " ToolMessage(content='36', name='multiply', tool_call_id='f09d3337-0574-4034-9d82-900b48ce1125'),\n",
       " ToolMessage(content='60', name='add', tool_call_id='3d89bbff-24d7-4032-b7b6-a4c12091d76f')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in ai_msg.tool_calls: #Actually running all the tool calls ai requested in last cell\n",
    "    tools_dict = {\"add\": add, \"multiply\": multiply}\n",
    "    selected_tool = tools_dict[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg) #Add the tool message to chat history\n",
    "\n",
    "messages\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b603e8e",
   "metadata": {},
   "source": [
    "#### Give final response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da446a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The result of 3 * 12 is 36. The result of 11 + 49 is 60.', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-08-24T22:41:50.491291Z', 'done': True, 'done_reason': 'stop', 'total_duration': 854849542, 'load_duration': 28822000, 'prompt_eval_count': 130, 'prompt_eval_duration': 241417875, 'eval_count': 25, 'eval_duration': 582864375, 'model_name': 'llama3.1'}, id='run--4f387296-9b21-434b-8a95-66897cfd5216-0', usage_metadata={'input_tokens': 130, 'output_tokens': 25, 'total_tokens': 155})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = llm_with_tools.invoke(messages)\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d85e0f",
   "metadata": {},
   "source": [
    "#### Just the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "680e4c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The result of 3 * 12 is 36. The result of 11 + 49 is 60.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ans.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
